import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import make_pipeline
from sklearn.metrics import r2_score, mean_absolute_error
import pickle
import warnings

# 1. Setup and Load Data
warnings.filterwarnings('ignore')
print("Loading dataset...")
housing_df = pd.read_csv('Final_Project.csv')

# 2. Data Cleaning & Preprocessing
# Drop irrelevant columns
cols_to_drop = ['Property_Name', 'Location', 'Availability', 'Bathroom']
housing_df = housing_df.drop(cols_to_drop, axis=1)

# Encode categorical variables
encoder = LabelEncoder()
categorical_cols = housing_df.select_dtypes(include=['object']).columns

for col in categorical_cols:
    housing_df[col] = encoder.fit_transform(housing_df[col])

# 3. Data Overview
print(f"\nProcessed Data Shape: {housing_df.shape}")
print("-" * 30)
print("Statistical Summary:")
print(housing_df.describe().round(2).T)

# 4. Correlation Visualization
plt.figure(figsize=(10, 8))
sns.heatmap(housing_df.corr(), annot=True, fmt=".2f", cmap='viridis', linewidths=0.5)
plt.title('Feature Correlation Matrix', fontsize=16)
plt.show()

# 5. Train-Test Split
X = housing_df.drop(['Price_Lakh'], axis=1)
y = housing_df['Price_Lakh']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"\nTraining set size: {X_train.shape[0]} samples")
print(f"Testing set size: {X_test.shape[0]} samples")

# 6. Model Comparison Loop
print("\n--- Baseline Model Comparison ---")
models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(min_samples_split=4, random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
}

for name, model in models.items():
    model.fit(X_train, y_train)
    train_acc = model.score(X_train, y_train)
    test_acc = model.score(X_test, y_test)
    print(f"{name:20} -> Train R2: {train_acc:.4f} | Test R2: {test_acc:.4f}")

# 7. Advanced Modeling (Polynomial Features + Random Forest)
print("\n--- Training Final Polynomial Model ---")
# Construct pipeline
poly_rf_model = make_pipeline(
    PolynomialFeatures(degree=2),
    RandomForestRegressor(n_estimators=500, max_depth=8, random_state=42)
)

# Fit model
poly_rf_model.fit(X_train, y_train)

# 8. Final Evaluation
def print_metrics(model, X_val, y_val):
    preds = model.predict(X_val)
    mae = mean_absolute_error(y_val, preds)
    r2 = r2_score(y_val, preds)
    print(f"Mean Absolute Error: {mae:.2f}")
    print(f"R^2 Accuracy: {r2:.4f}")

print_metrics(poly_rf_model, X_test, y_test)

# 9. Result Visualization
predictions = poly_rf_model.predict(X_test)
plt.figure(figsize=(10, 6))
sns.regplot(x=y_test, y=predictions, scatter_kws={'alpha':0.5, 'color':'blue'}, line_kws={'color':'red'})
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Actual vs Predicted Property Prices (Polynomial Model)")
plt.grid(True, alpha=0.3)
plt.show()

# 10. Save Model
filename = 'mumbai_real_estate_model.pkl'
with open(filename, 'wb') as file:
    pickle.dump(poly_rf_model, file)

print(f"\nModel successfully saved as '{filename}'")
